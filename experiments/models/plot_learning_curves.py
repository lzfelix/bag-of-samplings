import re
import argparse
from typing import List, Tuple, Dict

import numpy as np
import matplotlib
matplotlib.use('Agg')

import matplotlib.pyplot as plt

import compute_metrics as cm


def plot_with_std(amount_data, mean, std, label, color, fmt='-'):
    """Makes a line plot with the 1st std region shaded."""
    plt.plot(amount_data, mean, fmt, label=label, color=color)
    plt.fill_between(amount_data, mean - std, mean + std, alpha=0.2, color=color)


def parse_learning_curve_logs(logs_filepath: str) -> Tuple[Dict[str, float],
                                                           Dict[str, float]]:
    """Parses the log files generated by `learning_curve.py` and returns two dicts,
    one with training mean and other with std values."""
    AMOUNT_METRICS = 6

    def get_values(raw_metrics: List[str]) -> Tuple[List[float], List[float]]:
        means = list()
        stds = list()
        for entry in raw_metrics:
            # can't use regex because of nan values
            entry = re.sub(r'\s{2,}', ' ', entry)
            mean, _, std = entry.split()[1:4]

            mean = float(mean)
            mean = 0 if np.isnan(mean) else mean
            means.append(mean)

            std = float(std)
            std = 0 if np.isnan(std) else std
            stds.append(std)
        return means, stds

    def make_dict():
        return dict(accuracy=[], precision=[], recall=[], f1=[], acc_hc=[], acc_pd=[])
    
    def numpify_dict(d: Dict[str, list]) -> Dict[str, np.ndarray]:
        return {k: np.asarray(v) for k, v in d.items()}

    lines = open(logs_filepath).readlines()
    iterator = iter(lines)

    metrics_means = make_dict()
    metrics_stds = make_dict()
    amount_samples = list()
    for line in iterator:
        if 'Split: tst' in line:
            raw_metrics = [next(iterator).strip() for _ in range(AMOUNT_METRICS)]
            means, stds = get_values(raw_metrics)

            cm.store_metrics(metrics_means, means)
            cm.store_metrics(metrics_stds, stds)
        elif re.match('Training with \d+ samples', line):
            n_samples = re.findall(r'\d+', line)[0]
            amount_samples.append(int(n_samples))

    return amount_samples, numpify_dict(metrics_means), numpify_dict(metrics_stds)


def plot_metric_evolution(x, means, stds, metric, color, fmt='-', label=None):
    """Shorthand function to plot metrics with their stds."""
    label = label or metric.capitalize()
    plot_with_std(x, means[metric], stds[metric] + 0.01, label, color, fmt)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(usage='Plots model learning curves')
    parser.add_argument('-logs', help='Path to the output generated by learning_curve.py',
                        default='./lc_logs/mea_merged.txt')
    parser.add_argument('-dest', help='Where to store the plot',
                        default='../evolution_mea.pdf')
    exec_args = parser.parse_args()

    n_samples, means, stds = parse_learning_curve_logs(exec_args.logs)

    # If there are more samples than metrics, this means that the last run is still
    # in progress, so skip it.
    if len(means['accuracy']) < len(n_samples):
        n_samples = n_samples[:-1]

    # Plotting stuff
    plt.figure(figsize=(5, 4))
    plot_metric_evolution(n_samples, means, stds, 'accuracy', 'orange', fmt='-o')
    plot_metric_evolution(n_samples, means, stds, 'precision', 'cyan', fmt='-o')
    plot_metric_evolution(n_samples, means, stds, 'recall', 'red', fmt='-o')
    plot_metric_evolution(n_samples, means, stds, 'f1', 'blue', fmt='-o')
    plot_metric_evolution(n_samples, means, stds, 'acc_hc', 'black', fmt='--o', label='HC Accuracy')
    plot_metric_evolution(n_samples, means, stds, 'acc_pd', 'gray', fmt='--o', label='PD Accuracy')
    plt.legend(loc='lower right', fancybox=True)
    plt.xlabel('# Samples')
    plt.ylabel('Normalized metric')
    plt.grid(alpha=0.2)
    plt.ylim(0.4, 1)
    plt.savefig(exec_args.dest, bbox_inches='tight')
